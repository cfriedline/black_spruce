{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import izip\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import dill\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd ~/g/projects/black_spruce/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_needle_graphs = !ls *graph*all_needle*.txt\n",
    "all_cambium_graphs = !ls *graph*all_cambium*.txt\n",
    "\n",
    "dge_needle_graphs = !ls *graph*needle*.txt | grep -v 'all'\n",
    "dge_cambium_graphs = !ls *graph*cambium*.txt | grep -v 'all'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graphs = {\"Needle-All\": all_needle_graphs,\n",
    "          \"Cambium-All\": all_cambium_graphs,\n",
    "         \"Needle-DGE\":dge_needle_graphs,\n",
    "         \"Cambium-DGE\":dge_cambium_graphs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gentables = dill.load(open(\"gentables.dill\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gentables.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"notebook\", font_scale=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Write out unigenes that are present in each tissue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counts_file = \"seqclean/all_ests.fa.clean_output/contig_member.counts\"\n",
    "counts_df = pd.read_csv(counts_file, sep=\"\\t\", index_col=0)\n",
    "counts_df = counts_df.assign(C = lambda x: x.P32C + x.P40C > 0)\n",
    "counts_df = counts_df.assign(N = lambda x: x.P32N + x.P40N > 0)\n",
    "with open(\"needle_unigenes.txt\", \"w\") as o:\n",
    "    for elem in counts_df[counts_df.N].index.tolist():\n",
    "        o.write(\"%s\\n\" % elem)\n",
    "with open(\"cambium_unigenes.txt\", \"w\") as o:\n",
    "    for elem in counts_df[counts_df.C].index.tolist():\n",
    "        o.write(\"%s\\n\" % elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Generate blast2go combined graphs for each ontology\n",
    "\n",
    "* Sequence filter = 5\n",
    "* Graph coloring = by Node Score\n",
    "* Score alpha = 0.6\n",
    "* Node Score Filter = 5\n",
    "* Node Information = all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mpl.rcParams = mpl.rcParamsDefault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mpl.rcParams['svg.fonttype'] = 'svgfont'\n",
    "mpl.rcParams['font.sans-serif'] = ['Arial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mpl.rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_pie(plot_data, title, merged):\n",
    "    unique_seqs = set()\n",
    "    sig = \"\"\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(8,8)\n",
    "    labels = None\n",
    "\n",
    "    if merged:\n",
    "        plot_data['Label'] = plot_data.apply(lambda row: \"%s (%d)\" % (row[\"Term_x\"],row[\"#Seqs\"]), axis=1)\n",
    "        plot_data['sig1'] = plot_data.apply(lambda x: \"*\" if float(x.classicFisher) < 0.05 else \"\", axis=1)\n",
    "        plot_data['sig2'] = plot_data.apply(lambda x: \"*\" if x.bh == True else \"\", axis=1)\n",
    "        plot_data['siglabel'] = plot_data.apply(lambda row: \"%s%s%s\" % (row.Label, row.sig1, row.sig2), axis=1)\n",
    "        labels = plot_data['siglabel']\n",
    "    else:\n",
    "        plot_data['Label'] = plot_data.apply(lambda row: \"%s (%d)\" % (row[\"Term\"],row[\"#Seqs\"]), axis=1)\n",
    "        labels = plot_data['Label']\n",
    "        \n",
    "    sig_data = pd.DataFrame(plot_data[plot_data.Label != plot_data.siglabel])\n",
    "    plot_data = plot_data.ix[0:20,:]\n",
    "    plot_data = plot_data.append(sig_data)\n",
    "    plot_data = plot_data.drop_duplicates()\n",
    "    plot_data = plot_data.sort(\"#Seqs\", ascending=True)\n",
    "    plot_data['not_sig'] = plot_data.apply(lambda x: True if not \"*\" in x.siglabel else False, axis=1)\n",
    "        \n",
    "    \n",
    "    if len(plot_data) > 20:\n",
    "        to_delete = len(plot_data)-20\n",
    "        deleted = 0\n",
    "        delete_me = []\n",
    "        for row in plot_data.iterrows():\n",
    "            if row[1]['not_sig']:\n",
    "                delete_me.append(row[0])\n",
    "                deleted += 1\n",
    "            \n",
    "            if deleted == to_delete:\n",
    "                break\n",
    "        plot_data = plot_data.drop(delete_me)    \n",
    "    \n",
    "    plot_data = plot_data.sort(\"#Seqs\", ascending=False)\n",
    "    \n",
    "    if len(plot_data) > 20:\n",
    "        plot_data = plot_data.ix[0:20,:]\n",
    "    \n",
    "    labels = plot_data['siglabel']\n",
    "    \n",
    "    colors = sns.cubehelix_palette(len(plot_data), \n",
    "                                   start=.5, \n",
    "                                   rot=-1.5, \n",
    "                                   dark=.15, \n",
    "                                   light=1.0, \n",
    "                                   reverse=True)\n",
    "    \n",
    "    \n",
    "    plt.pie(plot_data[\"#Seqs\"],\n",
    "           colors=colors,\n",
    "           labels = labels)\n",
    "    \n",
    "    for row in plot_data.iterrows():\n",
    "        for seq in row[1].Sequences.split(\",\"):\n",
    "            unique_seqs.add(seq)\n",
    "    title = \"Top and significant terms for %s (%d)%s\"  % (title, len(unique_seqs), sig)\n",
    "    plt.title(title )\n",
    "    pdf_name = title.replace(\" \", \"_\").replace(\"/\", \"-\") + \".svg\"\n",
    "    print pdf_name\n",
    "    plt.savefig(pdf_name, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Generate the pie charts\n",
    "\n",
    "They are annotated as follows:\n",
    "\n",
    "* The top 20 go terms are added to the terms that are significant, dropping duplicates for cases where significant terms are in the top 20\n",
    "* if this number > 20, then the **not** significant terms are trimmed, starting with the term having the smallest number of associated unigenes, until there are a total of 20 go terms in the pie chart\n",
    "* If there are $\\le$ 20 terms after adding sigificant ones, no trimming is performed\n",
    "* If there are > 20 terms still remaining after processing non-sig. from the bottom up, then only top 20 are kept\n",
    "* \\* indicates that a term is significant at p < 0.05\n",
    "* \\*\\* indicates that a term is significant at p < 0.05 after BH multiple test correction\n",
    "* The numbers in parentheses mean the following:\n",
    "    * In the title, it is the number of unique unigenes in the chart\n",
    "    * In each term, it is the number of unigenes annotated to that term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_graph_file_by_level(key, g):\n",
    "    ontology = g[-6:-4].upper()\n",
    "    tissue = key.split(\"-\")[0].lower()\n",
    "    df = pd.read_csv(g, sep=\"\\t\", header=0, index_col=1)\n",
    "    genkey = \"%s-%s\" % (tissue, ontology)\n",
    "    merged = False\n",
    "    if genkey in gentables:\n",
    "        gt = gentables[genkey]['gt']\n",
    "        gt.index = gt['GO.ID']\n",
    "        df = df.merge(gt, left_index=True, right_index=True)\n",
    "        merged = True\n",
    "    for level, data in df.groupby(\"Level\"):\n",
    "        if level > 1:\n",
    "            d = data.sort(\"#Seqs\", ascending=False)\n",
    "            plot_pie(d, \"%s/%s/Level %d\" % (key, ontology, level), merged)\n",
    "            \n",
    "            \n",
    "def process_graph_file(key, g):\n",
    "    ontology = g[-6:-4].upper()\n",
    "    tissue = key.split(\"-\")[0].lower()\n",
    "    df = pd.read_csv(g, sep=\"\\t\", header=0, index_col=1)\n",
    "    genkey = \"%s-%s\" % (tissue, ontology)\n",
    "    merged = False\n",
    "    if genkey in gentables:\n",
    "        gt = gentables[genkey]['gt']\n",
    "        gt.index = gt['GO.ID']\n",
    "        df = df.merge(gt, left_index=True, right_index=True)\n",
    "        merged = True\n",
    "        d = df.sort(\"#Seqs\", ascending=False)\n",
    "        d = d[d.Level != 1]\n",
    "        plot_pie(d, \"%s/%s\" % (key, ontology), merged)\n",
    "            \n",
    "            \n",
    "plotted = 0\n",
    "for key, files in graphs.items():\n",
    "    if not \"DGE\" in key:\n",
    "        print \"================= Charts for %s =================\" % key\n",
    "        for g in files:\n",
    "            process_graph_file(key, g)\n",
    "            #process_graph_file_by_level(key, g)\n",
    "            plotted+=1      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key, files in graphs.items():\n",
    "    if key:\n",
    "        print \"================= Charts for %s =================\" % key\n",
    "        appended = pd.DataFrame(dtype=float)\n",
    "        for g in files:\n",
    "            ontology = g[-6:-4].upper()\n",
    "            tissue = key.split(\"-\")[0].lower()\n",
    "            df = pd.read_csv(g, sep=\"\\t\", header=0, index_col=1)\n",
    "            genkey = \"%s-%s\" % (tissue, ontology)\n",
    "            merged = False\n",
    "            if genkey in gentables:\n",
    "                gt = gentables[genkey]['gt']\n",
    "                gt.index = gt['GO.ID']\n",
    "                df = df.merge(gt, left_index=True, right_index=True)\n",
    "                merged = True\n",
    "                d = df.sort(\"#Seqs\", ascending=False)\n",
    "                appended = pd.concat([appended, d['classicFisher']])\n",
    "                #display(d)\n",
    "        appended = appended.astype(float) \n",
    "        revigo_file = \"revigo_%s.txt\" % key.lower()\n",
    "        print revigo_file\n",
    "        appended.to_csv(revigo_file, sep=\"\\t\", header=False)\n",
    "        \n",
    "        revigo_file = \"revigo_%s_sig.txt\" % key.lower()\n",
    "        print revigo_file\n",
    "        appended[appended[0]<0.05].to_csv(revigo_file, sep=\"\\t\", header=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}