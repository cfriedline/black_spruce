{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import izip\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import dill\n",
    "from IPython.display import display\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shell(cmd):\n",
    "    from subprocess import Popen, PIPE\n",
    "    p = Popen(cmd, shell=True, stdout=PIPE, stderr=PIPE)\n",
    "    stdout, stderr = p.communicate()\n",
    "    return [x for x in stdout.split(\"\\n\") if x != '']#, stderr.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd ~/g/projects/black_spruce_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##GO Graphs\n",
    "\n",
    "Generated as follows:\n",
    "\n",
    "1. filtered by unigene name according to expression in tissue > 0, including unigenes found in other tissues.\n",
    "1. Sequence filter (5)\n",
    "1. Graph-coloring (Node score)\n",
    "1. Score alpha (0.6)\n",
    "1. Node Score Filter (20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_needle_graphs = shell(\"ls *graph*20150707_1105*all_needle*.txt\")\n",
    "all_cambium_graphs = shell(\"ls *graph*20150707_1105*all_cambium*.txt\")\n",
    "\n",
    "#dge_needle_graphs = !ls *graph*20150511_1221*needle*.txt | grep -v 'all'\n",
    "#dge_cambium_graphs = !ls *graph*20150511_1221*cambium*.txt | grep -v 'all'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_needle_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# graphs = {\"Needle-All\": all_needle_graphs,\n",
    "#           \"Cambium-All\": all_cambium_graphs,\n",
    "#          \"Needle-DGE\":dge_needle_graphs,\n",
    "#          \"Cambium-DGE\":dge_cambium_graphs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graphs = {\"Needle-All\": all_needle_graphs,\n",
    "          \"Cambium-All\": all_cambium_graphs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shell(\"ls -lrt *.dill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gentables = dill.load(open(\"gentables.dill\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gentables.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"notebook\", font_scale=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Write out unigenes that are present in each tissue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counts_file = \"seqclean/all_ests.fa.clean_output/contig_member.counts\"\n",
    "counts_df = pd.read_csv(counts_file, sep=\"\\t\", index_col=0)\n",
    "counts_df = counts_df.assign(C = lambda x: x.P32C + x.P40C > 0)\n",
    "counts_df = counts_df.assign(N = lambda x: x.P32N + x.P40N > 0)\n",
    "with open(\"needle_unigenes.txt\", \"w\") as o:\n",
    "    for elem in counts_df[counts_df.N].index.tolist():\n",
    "        o.write(\"%s\\n\" % elem)\n",
    "with open(\"cambium_unigenes.txt\", \"w\") as o:\n",
    "    for elem in counts_df[counts_df.C].index.tolist():\n",
    "        o.write(\"%s\\n\" % elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Generate blast2go combined graphs for each ontology\n",
    "\n",
    "* Sequence filter = 5\n",
    "* Graph coloring = by Node Score\n",
    "* Score alpha = 0.6\n",
    "* Node Score Filter = 5\n",
    "* Node Information = all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mpl.rcParams = mpl.rcParamsDefault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mpl.rcParams['svg.fonttype'] = 'none'\n",
    "mpl.rcParams['font.sans-serif'] = ['Arial']\n",
    "mpl.rcParams['font.size'] = 40.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Generate the pie charts\n",
    "\n",
    "They are annotated as follows:\n",
    "\n",
    "* The top 20 go terms are added to the terms that are significant, dropping duplicates for cases where significant terms are in the top 20\n",
    "* if this number > 20, then the **not** significant terms are trimmed, starting with the term having the smallest number of associated unigenes, until there are a total of 20 go terms in the pie chart\n",
    "* If there are $\\le$ 20 terms after adding sigificant ones, no trimming is performed\n",
    "* If there are > 20 terms still remaining after processing non-sig. from the bottom up, then only top 20 are kept\n",
    "* \\* indicates that a term is significant at p < 0.05\n",
    "* \\*\\* indicates that a term is significant at p < 0.05 after BH multiple test correction\n",
    "* The numbers in parentheses mean the following:\n",
    "    * In the title, it is the number of unique unigenes in the chart\n",
    "    * In each term, it is the number of unigenes annotated to that term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_pie(plot_data, title, merged, top):\n",
    "    unique_seqs = set()\n",
    "    sig = \"\"\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(8,8)\n",
    "    labels = None\n",
    "    plot_data['classicFisher'] = plot_data['classicFisher'].astype(float)\n",
    "    if merged:\n",
    "        plot_data['Label'] = plot_data.apply(lambda row: \"%s (%d)\" % (row[\"Term_x\"],row[\"#Seqs\"]), axis=1)\n",
    "        plot_data['sig1'] = plot_data.apply(lambda x: \"*\" if float(x.classicFisher) < 0.05 else \"\", axis=1)\n",
    "        plot_data['sig2'] = plot_data.apply(lambda x: \"*\" if x.bh == True else \"\", axis=1)\n",
    "        plot_data['siglabel'] = plot_data.apply(lambda row: \"%s%s%s\" % (row.Label, row.sig1, row.sig2), axis=1)\n",
    "        labels = plot_data['siglabel']\n",
    "    else:\n",
    "        plot_data['Label'] = plot_data.apply(lambda row: \"%s (%d)\" % (row[\"Term\"],row[\"#Seqs\"]), axis=1)\n",
    "        labels = plot_data['Label']\n",
    "        \n",
    "    num_sig = len(plot_data[plot_data.classicFisher < 0.05])\n",
    "    num_bh = len(plot_data[plot_data.bh ==True])\n",
    "        \n",
    "    sig_data = pd.DataFrame(plot_data[plot_data.Label != plot_data.siglabel])\n",
    "    #plot_data = plot_data.ix[0:top,:]\n",
    "    plot_data = plot_data.append(sig_data)\n",
    "    plot_data = plot_data.drop_duplicates()\n",
    "    plot_data = plot_data.sort(\"#Seqs\", ascending=True)\n",
    "    plot_data['not_sig'] = plot_data.apply(lambda x: True if not \"*\" in x.siglabel else False, axis=1)\n",
    "        \n",
    "    \n",
    "    if len(plot_data) > top:\n",
    "        print \"trimming from %d to %d\" % (len(plot_data), top)\n",
    "        plot_data = plot_data.sort(\"#Seqs\")\n",
    "        plot_data[\"#Seqs\"]\n",
    "        to_delete = len(plot_data)-top\n",
    "        deleted = 0\n",
    "        delete_me = []\n",
    "        for row in plot_data.iterrows():\n",
    "            if row[1]['not_sig']:\n",
    "                delete_me.append(row[0])\n",
    "                deleted += 1\n",
    "            \n",
    "            if deleted == to_delete:\n",
    "                break\n",
    "        plot_data = plot_data.drop(delete_me)    \n",
    "    \n",
    "    plot_data = plot_data.sort(\"#Seqs\", ascending=False)\n",
    "    \n",
    "    if len(plot_data) > top:\n",
    "        plot_data = plot_data.ix[0:top,:]\n",
    "    \n",
    "    labels = plot_data['siglabel']\n",
    "    \n",
    "    colors = sns.cubehelix_palette(len(plot_data), \n",
    "                                   start=.5, \n",
    "                                   rot=-1.5, \n",
    "                                   dark=.15, \n",
    "                                   light=1.0, \n",
    "                                   reverse=True)\n",
    "    \n",
    "    \n",
    "    plt.pie(plot_data[\"#Seqs\"],\n",
    "           colors=colors,\n",
    "           labels = labels)\n",
    "    \n",
    "    for row in plot_data.iterrows():\n",
    "        for seq in row[1].Sequences.split(\",\"):\n",
    "            unique_seqs.add(seq)\n",
    "   \n",
    "    print num_sig, num_bh\n",
    "    title = \"The %d top and significant terms for %s (%d/%d/%d)\"  % (top, title, len(unique_seqs),\n",
    "                                                                    num_sig, num_bh)\n",
    "    \n",
    "    plt.title(title)\n",
    "    pdf_name = title.replace(\" \", \"_\").replace(\"/\", \"-\") + \".svg\"\n",
    "    plt.savefig(pdf_name, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def process_graph_file_by_level(key, g):\n",
    "    ontology = g[-6:-4].upper()\n",
    "    tissue = key.split(\"-\")[0].lower()\n",
    "    df = pd.read_csv(g, sep=\"\\t\", header=0, index_col=1)\n",
    "    genkey = \"%s-%s\" % (tissue, ontology)\n",
    "    merged = False\n",
    "    if genkey in gentables:\n",
    "        gt = gentables[genkey]['gt']\n",
    "        gt.index = gt['GO.ID']\n",
    "        df = df.merge(gt, left_index=True, right_index=True)\n",
    "        merged = True\n",
    "    for level, data in df.groupby(\"Level\"):\n",
    "        if level > 1:\n",
    "            d = data.sort(\"#Seqs\", ascending=False)\n",
    "            plot_pie(d, \"%s/%s/Level %d\" % (key, ontology, level), merged)\n",
    "            \n",
    "def correct_pvals(df):\n",
    "    return multipletests([float(x) for x in df.classicFisher], method=\"fdr_bh\")[0]\n",
    "            \n",
    "            \n",
    "def process_graph_file(key, g, top):\n",
    "    ontology = g[-6:-4].upper()\n",
    "    tissue = key.split(\"-\")[0].lower()\n",
    "    df = pd.read_csv(g, sep=\"\\t\", header=0, index_col=1)\n",
    "    genkey = \"%s-%s\" % (tissue, ontology)\n",
    "    print genkey\n",
    "    merged = False\n",
    "    if genkey in gentables:\n",
    "        gt = gentables[genkey]['gt']\n",
    "        gt.index = gt['GO.ID']\n",
    "        df = df.merge(gt, left_index=True, right_index=True)\n",
    "        merged = True\n",
    "        d = df.sort(\"#Seqs\", ascending=False)\n",
    "        d = d[d.Level != 1]\n",
    "        d['bh'] = correct_pvals(d)\n",
    "        plot_pie(d, \"%s/%s\" % (key, ontology), merged, top)\n",
    "            \n",
    "            \n",
    "plotted = 0\n",
    "for key, files in graphs.items():\n",
    "    d = key.split(\"-\")\n",
    "    key = \"%s_all-%s\" % (d[0], d[1])\n",
    "    if not \"DGE\" in key:\n",
    "        print \"================= Charts for %s =================\" % key\n",
    "        for g in files:\n",
    "            process_graph_file(key, g, 30)\n",
    "            #process_graph_file_by_level(key, g)\n",
    "            plotted+=1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": "0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}